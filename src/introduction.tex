\section{Introduction}
Across a wide variety of applications and domains, graphs emerge as a domain-independent and ubiquitous way of organizing structured data. Consequently, machine learning on graphs has, in recent years, seen an explosion in popularity, breadth and depth of both research and applications. While there have been significant advances in algorithms for learning from graph data \cite{defferrard_convolutional_2016,kipf_semi-supervised_2017}, the underlying graph topology has, until recent works \cite{topping_understanding_2021,velickovic_geometric_2021}, received much less attention. In the reported research, we investigate the interplay of graph coarsening and the quality of its learned embedding (as studied, for example, by \cite{akyildiz_understanding_2020,makarov_survey_2021}), which in turn entails an interplay between the coarsening and the performance of a downstream task, in our case, node classification.

The main aim of this work is to explore the performance-complexity characteristics in the context of graph learning, as introduced in \cite{prochazka_downstream_2022}. Consider an undirected graph \( G \) with nodes \( V \left( G \right) \) and edges \( E \left( G \right) \). The result of a repeated application of graph coarsening is a sequence of graphs \( G_0, G_1, G_2, \dots, G_L \) where \( G_0 = G \).
Given a model \( M \) that operates on graphs, a performance metric, and a complexity metric, the sequence \( G_0, G_1, \dots, G_L \) corresponds to points in the performance-complexity plane, where advancing along the sequence generally hurts performance and decreases complexity.

This performance-complexity characteristic allows for a choice of a \textbf{working point} that is optimal for the particular use-case. In this work, the transductive node classification accuracy on a testing dataset is chosen as the performance metric. For the complexity metric, the number of nodes in the graph was chosen as it constitutes a good proxy for real-world algorithmic complexity, as shown in \cite{chiang_cluster-gcn_2019}. The method proposed in the rest of this work evaluates the graphs in reverse order, i.e. starting with the simplest one. Due to this, the algorithm allows for lower complexity of selecting the working point, despite repeated evalueations of the model. Further discussion of the performance-complexity trade-off problem is considered in \cite{prochazka_downstream_2022}.
